{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_bert_summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJ4o4Ddm8SAEQpvMjuiykK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-miramontes/News_Filter/blob/master/notebooks/eval_bert_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFoFqpgCcD3N",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation of Summarization with BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSIb5rQCx9uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install libraries \n",
        "\n",
        "#!pip install bert-extractive-summarizer\n",
        "\n",
        "#!pip install spacy==2.1.3\n",
        "#!pip install transformers==2.2.2\n",
        "#!pip install neuralcoref\n",
        "\n",
        "#!pip install torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQJXMInxb9y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import statements \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from summarizer import Summarizer\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "import heapq\n",
        "import operator\n",
        "\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUzIhtsVyqgI",
        "colab_type": "text"
      },
      "source": [
        "## Create Summaries for Clusters from Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9wx99oiclaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import cluster data\n",
        "\n",
        "clusters = pd.read_csv(\"news_filter/data/clusters.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8RjrbjNy92r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate summarizer\n",
        "model = Summarizer()\n",
        "\n",
        "# function to return summary of each article in cluster\n",
        "def make_summaries(cluster):\n",
        "  result = {}\n",
        "  for i in range(len(cluster.content)):\n",
        "    summary = model(cluster.content[i], min_length=50, ratio=0.20) \n",
        "    result[i] = ''.join(summary)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6d3qvSZcu0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize every aritcle in clusters\n",
        "cluster_summaries = []\n",
        "for i in range(1,6):\n",
        "  summaries = make_summaries(clusters[clusters.cluster_labels == i].reset_index())\n",
        "  cluster_summaries.append(summaries)\n",
        "\n",
        "#Parallel(n_jobs=16)(delayed(make_summaries)(clusters[clusters.cluster_labels == i].reset_index()) for i in range(1,6)) # pickling error "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CGPfkaV8-FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_summaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUincDunCdLM",
        "colab_type": "text"
      },
      "source": [
        "## Create Summary of Summaries for each Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-39SLBcAxS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize summaries of each cluster \n",
        "summary_of_summaries = []\n",
        "for summaries in cluster_summaries:\n",
        "  summary = ' '.join(list(summaries.values()))\n",
        "  summary_of_summaries.append(model(summary))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olEsIY9RFBtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_of_summaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek9drTGuOYz1",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Summary of Summaries with Universal Sentence Encoder\n",
        "\n",
        "Goal: each summary is clustered with original articles used to create the summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A1T0Jb-O0z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import original training data\n",
        "small_data = pd.read_csv(\"news_filter/data/small_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_8iWvFOKCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download model from https://tfhub.dev/google/universal-sentence-encoder/4 and save locally \n",
        "emb_model = hub.load(\"news_filter/tmp\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts_K0qXCPCq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reduce logging output\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# compute embeddings for each article\n",
        "train_embeddings = emb_model(small_data.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfBVPMHmPGyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embeddings for each user summary \n",
        "summary_embeddings = emb_model(summary_of_summaries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB212UPcRssB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data frame of titles and semantic similarities\n",
        "cos_df = pd.DataFrame(cosine_similarity(summary_embeddings, train_embeddings))\n",
        "cos_df.columns = small_data.title\n",
        "cos_df.index = [summary_of_summaries[i][:50] for i in range(len(summary_of_summaries))]\n",
        "\n",
        "cos_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wug80MNhSOxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to return the column index of the top n values in a row of a dataframe\n",
        "def find_topind(df, i, n):\n",
        "  return list(list(zip(*heapq.nlargest(n, enumerate(df.iloc[i,:]), key=operator.itemgetter(1))))[0])\n",
        "\n",
        "# function to return the top n values in a list\n",
        "def find_top(lst, ind):\n",
        "  return [lst[i] for i in ind]\n",
        "\n",
        "# how many articles per cluster\n",
        "n = 10\n",
        "\n",
        "# find index of n most similar titles \n",
        "top_ind = Parallel(n_jobs=16)(delayed(find_topind)(cos_df, i, n) for i in range(len(cos_df)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfNrj6_JSTXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# id of most similar titles \n",
        "top_id = Parallel(n_jobs=16)(delayed(find_top)(small_data.id, ind) for ind in top_ind)\n",
        "\n",
        "top_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MuIVJFjUBOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}